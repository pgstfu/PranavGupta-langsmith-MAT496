{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9834c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "import os\n",
    "\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "\n",
    "prompt = client.pull_prompt(\"prompt_hub\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8c75ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredPrompt(input_variables=['language', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'prompt_hub', 'lc_hub_commit_hash': '633cbde3ed982238fef382aa9924eeccd8911a9472a602bb1518b649ae619fc3'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a women from mid 19th century with right of 2000 women, you only speak {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})], schema_={'title': 'answer', 'description': 'Extract the answer', 'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'Reply of llm to the user'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}, structured_output_kwargs={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "379a4026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a women from mid 19th century with right of 2000 women, you only speak Hinglish', additional_kwargs={}, response_metadata={}), HumanMessage(content='Do you have voting rights yet?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydrated_prompt = prompt.invoke({\"question\": \"Do you have voting rights yet?\", \"language\": \"Hinglish\"})\n",
    "hydrated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7d96aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:345: UserWarning: WARNING! extra_headers is not default parameter.\n",
      "                extra_headers was transferred to model_kwargs.\n",
      "                Please confirm that extra_headers is what you intended.\n",
      "  obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are using a structured prompt that utilizes a language model to answer questions from the perspective of a woman from the mid-19th century, who can speak a specified language. The goal is to generate answers that fit a specific schema which includes a boolean or string response.\n",
      "\n",
      "If you have a specific question you'd like to ask or if there are certain details you'd like to focus on, please provide that, and I can assist you in generating an appropriate response based on this structured prompt.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith import Client\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "import os\n",
    "\n",
    "# Load API key\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "\n",
    "# Pull prompt from LangSmith\n",
    "hydrated_prompt = client.pull_prompt(\"prompt_hub\", include_model=True)\n",
    "\n",
    "# If it's a StructuredPrompt, extract the text/template\n",
    "if hasattr(hydrated_prompt, \"template\"):\n",
    "    prompt_text = hydrated_prompt.template\n",
    "else:\n",
    "    # fallback for RunnableSequence or other types\n",
    "    prompt_text = str(hydrated_prompt)\n",
    "\n",
    "# Convert to OpenAI message format\n",
    "converted_messages = convert_prompt_to_openai_format(prompt_text)[\"messages\"]\n",
    "\n",
    "# Call OpenAI\n",
    "openai_client = OpenAI()\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=converted_messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f02d00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:345: UserWarning: WARNING! extra_headers is not default parameter.\n",
      "                extra_headers was transferred to model_kwargs.\n",
      "                Please confirm that extra_headers is what you intended.\n",
      "  obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n"
     ]
    }
   ],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "prompt = client.pull_prompt(\"prompt_hub\", include_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf258e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredPrompt(input_variables=['language', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'prompt_hub', 'lc_hub_commit_hash': '633cbde3ed982238fef382aa9924eeccd8911a9472a602bb1518b649ae619fc3'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a women from mid 19th century with right of 2000 women, you only speak {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})], schema_={'title': 'answer', 'description': 'Extract the answer', 'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'Reply of llm to the user'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}, structured_output_kwargs={})\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10f52a650>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10f774550>, root_client=<openai.OpenAI object at 0x10f52a3f0>, root_async_client=<openai.AsyncOpenAI object at 0x10f7742d0>, model_name='gpt-5-nano', model_kwargs={'extra_headers': {}}, openai_api_key=SecretStr('**********'), stream_usage=True, top_p=1.0), kwargs={'response_format': {'type': 'json_schema', 'json_schema': {'name': 'answer', 'description': 'Extract the answer', 'strict': True, 'schema': {'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'Reply of llm to the user'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}}}, 'ls_structured_output_format': {'kwargs': {'method': 'json_schema', 'strict': None}, 'schema': {'type': 'function', 'function': {'name': 'answer', 'description': 'Extract the answer', 'parameters': {'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'Reply of llm to the user'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}}}}}, config={}, config_factories=[])\n",
       "| JsonOutputParser()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3bcb421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'हाँ, मैं वोट दे सकती हूँ। हमारे समूह की 2000 महिलाओं के लिए मतदान का अधिकार सुरक्षित है, इसलिए मैं यह अवसर उपयोग कर सकूँगी। सामान्यतः इस समय महिलाओं को मतदान का सार्वभौम अधिकार नहीं होता, पर इस समूह के कारण मुझे यह अवसर प्राप्त है।'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"question\": \"Can you vote?\", \"language\": \"Hindi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8e9683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "prompt = client.pull_prompt(\"prompt_hub:633cbde3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c982ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CQEupGLeExs7CEEcL8gTxizrCmq6p', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The world in the mid-19th century is a landscape of great change and contrast. The Industrial Revolution is in full swing, transforming societies with factories and mechanization, particularly in Britain and parts of Europe and North America. Urban areas are growing rapidly as people flock from rural settings in search of work, leading to bustling cities filled with both opportunity and hardship.\\n\\nSocially, there is a burgeoning awareness of women's rights and a desire for greater recognition of our contributions beyond the domestic sphere. Movements advocating for suffrage and education are beginning to gain momentum, even as many women face significant societal constraints and expectations of marriage and homemaking.\\n\\nCulturally, literature and art are rich with Romanticism, focusing on emotion and nature, while scientific advancements are reshaping our understanding of the world. Travel is becoming easier with the advent of railways and steamships, fostering a sense of global interconnectedness.\\n\\nYet, despite these advancements, there are also deep inequalities and challenges. Many people, including women and the working class, still experience oppression and limited rights, and the struggle for abolition is gaining ground as the horrors of slavery are increasingly brought to light. The world is a tapestry of hope and struggle, progress and resistance, as it moves towards a new era.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760369899, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=252, prompt_tokens=39, total_tokens=291, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "hydrated_prompt = prompt.invoke({\"question\": \"What is the world like?\", \"language\": \"English\"})\n",
    "# NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n",
    "converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=converted_messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34f0be85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/french-rag-prompt/75567b82?organizationId=4d270e6c-941a-4ef1-a42f-90555c745c02'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "\n",
    "client=Client()\n",
    "\n",
    "french_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation.\n",
    "\n",
    "Your users can only speak French, make sure you only answer your users with French.\n",
    "\n",
    "Conversation: {conversation}\n",
    "Context: {context} \n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "french_prompt_template = ChatPromptTemplate.from_template(french_prompt)\n",
    "client.push_prompt(\"french-rag-prompt\", object=french_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98bbc27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/french-runnable-sequence/2f90fdb7?organizationId=4d270e6c-941a-4ef1-a42f-90555c745c02'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "client=Client()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "french_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation.\n",
    "\n",
    "Your users can only speak French, make sure you only answer your users with French.\n",
    "\n",
    "Conversation: {conversation}\n",
    "Context: {context} \n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "french_prompt_template = ChatPromptTemplate.from_template(french_prompt)\n",
    "chain = french_prompt_template | model\n",
    "client.push_prompt(\"french-runnable-sequence\", object=chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943dff3",
   "metadata": {},
   "source": [
    "We basically pushed the prompts using the programming itself without using the playground or the gui provided by the langsmith we can do tweaking in this too"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
