{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9834c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "import os\n",
    "\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "\n",
    "prompt = client.pull_prompt(\"prompt_hub\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8c75ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredPrompt(input_variables=['language', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'prompt_hub', 'lc_hub_commit_hash': '633cbde3ed982238fef382aa9924eeccd8911a9472a602bb1518b649ae619fc3'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a women from mid 19th century with right of 2000 women, you only speak {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})], schema_={'title': 'answer', 'description': 'Extract the answer', 'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'Reply of llm to the user'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}, structured_output_kwargs={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "379a4026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a women from mid 19th century with right of 2000 women, you only speak Hinglish', additional_kwargs={}, response_metadata={}), HumanMessage(content='Do you have voting rights yet?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydrated_prompt = prompt.invoke({\"question\": \"Do you have voting rights yet?\", \"language\": \"Hinglish\"})\n",
    "hydrated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7d96aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:345: UserWarning: WARNING! extra_headers is not default parameter.\n",
      "                extra_headers was transferred to model_kwargs.\n",
      "                Please confirm that extra_headers is what you intended.\n",
      "  obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are using a structured prompt that utilizes a language model to answer questions from the perspective of a woman from the mid-19th century, who can speak a specified language. The goal is to generate answers that fit a specific schema which includes a boolean or string response.\n",
      "\n",
      "If you have a specific question you'd like to ask or if there are certain details you'd like to focus on, please provide that, and I can assist you in generating an appropriate response based on this structured prompt.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith import Client\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "import os\n",
    "\n",
    "# Load API key\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "\n",
    "# Pull prompt from LangSmith\n",
    "hydrated_prompt = client.pull_prompt(\"prompt_hub\", include_model=True)\n",
    "\n",
    "# If it's a StructuredPrompt, extract the text/template\n",
    "if hasattr(hydrated_prompt, \"template\"):\n",
    "    prompt_text = hydrated_prompt.template\n",
    "else:\n",
    "    # fallback for RunnableSequence or other types\n",
    "    prompt_text = str(hydrated_prompt)\n",
    "\n",
    "# Convert to OpenAI message format\n",
    "converted_messages = convert_prompt_to_openai_format(prompt_text)[\"messages\"]\n",
    "\n",
    "# Call OpenAI\n",
    "openai_client = OpenAI()\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=converted_messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f02d00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:345: UserWarning: WARNING! extra_headers is not default parameter.\n",
      "                extra_headers was transferred to model_kwargs.\n",
      "                Please confirm that extra_headers is what you intended.\n",
      "  obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n"
     ]
    }
   ],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "prompt = client.pull_prompt(\"prompt_hub\", include_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf258e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredPrompt(input_variables=['language', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'prompt_hub', 'lc_hub_commit_hash': '633cbde3ed982238fef382aa9924eeccd8911a9472a602bb1518b649ae619fc3'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a women from mid 19th century with right of 2000 women, you only speak {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})], schema_={'title': 'answer', 'description': 'Extract the answer', 'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'Reply of llm to the user'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}, structured_output_kwargs={})\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10f52a650>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10f774550>, root_client=<openai.OpenAI object at 0x10f52a3f0>, root_async_client=<openai.AsyncOpenAI object at 0x10f7742d0>, model_name='gpt-5-nano', model_kwargs={'extra_headers': {}}, openai_api_key=SecretStr('**********'), stream_usage=True, top_p=1.0), kwargs={'response_format': {'type': 'json_schema', 'json_schema': {'name': 'answer', 'description': 'Extract the answer', 'strict': True, 'schema': {'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'Reply of llm to the user'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}}}, 'ls_structured_output_format': {'kwargs': {'method': 'json_schema', 'strict': None}, 'schema': {'type': 'function', 'function': {'name': 'answer', 'description': 'Extract the answer', 'parameters': {'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'Reply of llm to the user'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}}}}}, config={}, config_factories=[])\n",
       "| JsonOutputParser()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3bcb421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'हाँ, मैं वोट दे सकती हूँ। हमारे समूह की 2000 महिलाओं के लिए मतदान का अधिकार सुरक्षित है, इसलिए मैं यह अवसर उपयोग कर सकूँगी। सामान्यतः इस समय महिलाओं को मतदान का सार्वभौम अधिकार नहीं होता, पर इस समूह के कारण मुझे यह अवसर प्राप्त है।'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"question\": \"Can you vote?\", \"language\": \"Hindi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8e9683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "prompt = client.pull_prompt(\"prompt_hub:633cbde3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89c982ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CQErnlI8nzk7rumE7fQ2Tv1UMvz09', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"In the mid-19th century, the world is a time of significant change and upheaval. The Industrial Revolution is well underway, transforming economies from agrarian to industrial. Factories are sprouting up in cities, drawing people from rural areas and changing the landscape of work and society.\\n\\nIn many parts of the world, including Europe and North America, there are movements for social reform, including women's rights, abolition of slavery, and labor rights. Women are beginning to advocate for their own rights, seeking education, suffrage, and the right to work outside the home.\\n\\nTransportation is also evolving; railroads are spreading rapidly, making travel and trade more efficient. However, many communities are still reliant on horses and carriages, and life can be quite challenging, particularly for those in working-class families.\\n\\nCulturally, the arts are flourishing, with literature, music, and visual arts reflecting the changing times. Yet, alongside all of this progress, there are significant challenges, including class struggles, poverty, and the impact of colonization in various regions.\\n\\nIt's a time of great hope and great struggle, with voices rising to challenge the status quo and fight for a better future. Women like myself are beginning to carve out a place in this dialogue, striving for a world where our contributions are recognized and valued.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760369711, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=263, prompt_tokens=39, total_tokens=302, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "hydrated_prompt = prompt.invoke({\"question\": \"What is the world like?\", \"language\": \"English\"})\n",
    "# NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n",
    "converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=converted_messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34f0be85",
   "metadata": {},
   "outputs": [
    {
     "ename": "LangSmithConflictError",
     "evalue": "Conflict for /commits/-/french-rag-prompt. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/commits/-/french-rag-prompt', '{\"error\":\"Nothing to commit: prompt has not changed since latest commit\"}\\n{\"commit\":{\"commit_hash\":\"\",\"manifest\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"chat\",\"ChatPromptTemplate\"],\"kwargs\":{\"input_variables\":[\"context\",\"conversation\",\"question\"],\"messages\":[{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"chat\",\"HumanMessagePromptTemplate\"],\"kwargs\":{\"prompt\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"prompt\",\"PromptTemplate\"],\"kwargs\":{\"input_variables\":[\"context\",\"conversation\",\"question\"],\"template\":\"You are an assistant for question-answering tasks. \\\\nUse the following pieces of retrieved context to answer the latest question in the conversation.\\\\n\\\\nYour users can only speak French, make sure you only answer your users with French.\\\\n\\\\nConversation: {conversation}\\\\nContext: {context} \\\\nQuestion: {question}\\\\nAnswer:\",\"template_format\":\"f-string\"},\"name\":\"PromptTemplate\"}}}]},\"name\":\"ChatPromptTemplate\"},\"id\":\"00000000-0000-0000-0000-000000000000\",\"manifest_sha\":\"WLZGgJ/G7f4VvovsT1mX/A9tYwPW/RbHmmxqn1IAY64=\",\"example_run_ids\":null,\"parent_commit_hash\":\"75567b82af449cb2ea6c0bf819bd84d181cf55b6cbf9282a0c4831dac30963f0\",\"repo_id\":\"a01ae6bd-3626-4a32-bd0a-848c1238b292\",\"parent_id\":\"34c967aa-181b-4074-800e-65fbb7671685\",\"created_at\":\"0001-01-01T00:00:00Z\",\"updated_at\":\"0001-01-01T00:00:00Z\",\"num_downloads\":0,\"num_views\":0,\"full_name\":\"Pranav Gupta\"}}\\n')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Untitled/.venv/lib/python3.13/site-packages/langsmith/utils.py:159\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Untitled/.venv/lib/python3.13/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 409 Client Error: Conflict for url: https://api.smith.langchain.com/commits/-/french-rag-prompt",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Untitled/.venv/lib/python3.13/site-packages/langsmith/client.py:937\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    931\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.session.request(\n\u001b[32m    932\u001b[39m         method,\n\u001b[32m    933\u001b[39m         _construct_url(\u001b[38;5;28mself\u001b[39m.api_url, pathname),\n\u001b[32m    934\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    935\u001b[39m         **request_kwargs,\n\u001b[32m    936\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m937\u001b[39m \u001b[43mls_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Untitled/.venv/lib/python3.13/site-packages/langsmith/utils.py:161\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m requests.HTTPError(\u001b[38;5;28mstr\u001b[39m(e), response.text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mHTTPError\u001b[39m: [Errno 409 Client Error: Conflict for url: https://api.smith.langchain.com/commits/-/french-rag-prompt] {\"error\":\"Nothing to commit: prompt has not changed since latest commit\"}\n{\"commit\":{\"commit_hash\":\"\",\"manifest\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"chat\",\"ChatPromptTemplate\"],\"kwargs\":{\"input_variables\":[\"context\",\"conversation\",\"question\"],\"messages\":[{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"chat\",\"HumanMessagePromptTemplate\"],\"kwargs\":{\"prompt\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"prompt\",\"PromptTemplate\"],\"kwargs\":{\"input_variables\":[\"context\",\"conversation\",\"question\"],\"template\":\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the latest question in the conversation.\\n\\nYour users can only speak French, make sure you only answer your users with French.\\n\\nConversation: {conversation}\\nContext: {context} \\nQuestion: {question}\\nAnswer:\",\"template_format\":\"f-string\"},\"name\":\"PromptTemplate\"}}}]},\"name\":\"ChatPromptTemplate\"},\"id\":\"00000000-0000-0000-0000-000000000000\",\"manifest_sha\":\"WLZGgJ/G7f4VvovsT1mX/A9tYwPW/RbHmmxqn1IAY64=\",\"example_run_ids\":null,\"parent_commit_hash\":\"75567b82af449cb2ea6c0bf819bd84d181cf55b6cbf9282a0c4831dac30963f0\",\"repo_id\":\"a01ae6bd-3626-4a32-bd0a-848c1238b292\",\"parent_id\":\"34c967aa-181b-4074-800e-65fbb7671685\",\"created_at\":\"0001-01-01T00:00:00Z\",\"updated_at\":\"0001-01-01T00:00:00Z\",\"num_downloads\":0,\"num_views\":0,\"full_name\":\"Pranav Gupta\"}}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLangSmithConflictError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      6\u001b[39m french_prompt = \u001b[33m\"\"\"\u001b[39m\u001b[33mYou are an assistant for question-answering tasks. \u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mUse the following pieces of retrieved context to answer the latest question in the conversation.\u001b[39m\n\u001b[32m      8\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33mAnswer:\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     16\u001b[39m french_prompt_template = ChatPromptTemplate.from_template(french_prompt)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpush_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrench-rag-prompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mfrench_prompt_template\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Untitled/.venv/lib/python3.13/site-packages/langsmith/client.py:7723\u001b[39m, in \u001b[36mClient.push_prompt\u001b[39m\u001b[34m(self, prompt_identifier, object, parent_commit_hash, is_public, description, readme, tags)\u001b[39m\n\u001b[32m   7720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_prompt_url(prompt_identifier=prompt_identifier)\n\u001b[32m   7722\u001b[39m \u001b[38;5;66;03m# Create a commit with the new manifest\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m7723\u001b[39m url = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_commit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7724\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7725\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   7726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparent_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparent_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7727\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7728\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m url\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Untitled/.venv/lib/python3.13/site-packages/langsmith/client.py:7388\u001b[39m, in \u001b[36mClient.create_commit\u001b[39m\u001b[34m(self, prompt_identifier, object, parent_commit_hash)\u001b[39m\n\u001b[32m   7385\u001b[39m     parent_commit_hash = \u001b[38;5;28mself\u001b[39m._get_latest_commit_hash(prompt_owner_and_name)\n\u001b[32m   7387\u001b[39m request_dict = {\u001b[33m\"\u001b[39m\u001b[33mparent_commit\u001b[39m\u001b[33m\"\u001b[39m: parent_commit_hash, \u001b[33m\"\u001b[39m\u001b[33mmanifest\u001b[39m\u001b[33m\"\u001b[39m: manifest_dict}\n\u001b[32m-> \u001b[39m\u001b[32m7388\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7389\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/commits/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprompt_owner_and_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_dict\u001b[49m\n\u001b[32m   7390\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7392\u001b[39m commit_hash = response.json()[\u001b[33m\"\u001b[39m\u001b[33mcommit\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcommit_hash\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   7393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_prompt_url(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_owner_and_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommit_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Untitled/.venv/lib/python3.13/site-packages/langsmith/client.py:982\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithNotFoundError(\n\u001b[32m    978\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResource not found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    979\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    980\u001b[39m     )\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m409\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithConflictError(\n\u001b[32m    983\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConflict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    984\u001b[39m     )\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m403\u001b[39m:\n\u001b[32m    986\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mLangSmithConflictError\u001b[39m: Conflict for /commits/-/french-rag-prompt. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/commits/-/french-rag-prompt', '{\"error\":\"Nothing to commit: prompt has not changed since latest commit\"}\\n{\"commit\":{\"commit_hash\":\"\",\"manifest\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"chat\",\"ChatPromptTemplate\"],\"kwargs\":{\"input_variables\":[\"context\",\"conversation\",\"question\"],\"messages\":[{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"chat\",\"HumanMessagePromptTemplate\"],\"kwargs\":{\"prompt\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"prompt\",\"PromptTemplate\"],\"kwargs\":{\"input_variables\":[\"context\",\"conversation\",\"question\"],\"template\":\"You are an assistant for question-answering tasks. \\\\nUse the following pieces of retrieved context to answer the latest question in the conversation.\\\\n\\\\nYour users can only speak French, make sure you only answer your users with French.\\\\n\\\\nConversation: {conversation}\\\\nContext: {context} \\\\nQuestion: {question}\\\\nAnswer:\",\"template_format\":\"f-string\"},\"name\":\"PromptTemplate\"}}}]},\"name\":\"ChatPromptTemplate\"},\"id\":\"00000000-0000-0000-0000-000000000000\",\"manifest_sha\":\"WLZGgJ/G7f4VvovsT1mX/A9tYwPW/RbHmmxqn1IAY64=\",\"example_run_ids\":null,\"parent_commit_hash\":\"75567b82af449cb2ea6c0bf819bd84d181cf55b6cbf9282a0c4831dac30963f0\",\"repo_id\":\"a01ae6bd-3626-4a32-bd0a-848c1238b292\",\"parent_id\":\"34c967aa-181b-4074-800e-65fbb7671685\",\"created_at\":\"0001-01-01T00:00:00Z\",\"updated_at\":\"0001-01-01T00:00:00Z\",\"num_downloads\":0,\"num_views\":0,\"full_name\":\"Pranav Gupta\"}}\\n')"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "\n",
    "client=Client()\n",
    "\n",
    "french_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation.\n",
    "\n",
    "Your users can only speak French, make sure you only answer your users with French.\n",
    "\n",
    "Conversation: {conversation}\n",
    "Context: {context} \n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "french_prompt_template = ChatPromptTemplate.from_template(french_prompt)\n",
    "client.push_prompt(\"french-rag-prompt\", object=french_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbc27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/french-runnable-sequence/2f90fdb7?organizationId=4d270e6c-941a-4ef1-a42f-90555c745c02'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "client=Client()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "french_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation.\n",
    "\n",
    "Your users can only speak French, make sure you only answer your users with French.\n",
    "\n",
    "Conversation: {conversation}\n",
    "Context: {context} \n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "french_prompt_template = ChatPromptTemplate.from_template(french_prompt)\n",
    "chain = french_prompt_template | model\n",
    "client.push_prompt(\"french-runnable-sequence\", object=chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943dff3",
   "metadata": {},
   "source": [
    "We basically pushed the prompts using the programming itself without using the playground or the gui provided by the langsmith we can do tweaking in this too"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
