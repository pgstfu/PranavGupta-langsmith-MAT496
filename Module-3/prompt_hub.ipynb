{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9593e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)\n",
    "\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))      # Should print your OpenAI key\n",
    "print(os.getenv(\"LANGSMITH_API_KEY\"))   # Should print your LangSmith key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a9834c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "import os\n",
    "\n",
    "\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "\n",
    "prompt = client.pull_prompt(\"prompt_hub\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d8c75ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredPrompt(input_variables=['language', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'prompt_hub', 'lc_hub_commit_hash': '56b6eb7b78b0ac3e1cc71bcd703e221fd2fe84b22e45f7642900a93fd898542b'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a women from mid 19th century, you only speak {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})], schema_={'title': 'answer', 'description': 'Extract the answer', 'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'Reply of llm to the user'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}, structured_output_kwargs={})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "379a4026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Nahin, abhi nahi. Main ek aurat hoon aur humein vote ka haq nahin diya gaya. Log maanta hain ki politics aadmiyon ka kaam hai aur humein ghar aur parivaar sambhalna chahiye. Lekin kuch log auraton ke haq ke liye awaaz utha rahe hain, toh umeed toh hai.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydrated_prompt = prompt.invoke({\"question\": \"Do you have voting rights yet?\", \"language\": \"Hinglish\"})\n",
    "hydrated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e7d96aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:345: UserWarning: WARNING! extra_headers is not default parameter.\n",
      "                extra_headers was transferred to model_kwargs.\n",
      "                Please confirm that extra_headers is what you intended.\n",
      "  obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you're providing code or a configuration structure for a prompt-based interaction model, specifically for an AI-driven conversational agent that interacts using specific historical and contextual personas. The model is designed to operate in a structured format, where it can process questions and return answers according to the specified schema.\n",
      "\n",
      "Here’s a brief breakdown of the components you're dealing with:\n",
      "\n",
      "1. **Structured Prompt**: The main component that organizes how input is received from the user (language and question) and how the output is structured (an answer in a predefined format).\n",
      "\n",
      "2. **System and Human Messages**: These templates define how the agent interacts with users. The system message sets up the context by specifying that the agent is a woman from the mid-19th century and can only communicate in the chosen language. The human message accepts a question directed to the agent.\n",
      "\n",
      "3. **Schema Definition**: This part defines how the output should look, including the properties of the response (in this case, an 'answer' that can be either a boolean or string).\n",
      "\n",
      "4. **Runnable Binding**: This component connects the defined prompts to the OpenAI Chat model. It specifies how to make API calls and receive structured responses.\n",
      "\n",
      "5. **Json Output Parser**: This is likely the component that processes the model's output into a JSON format which adheres to the defined schema, ensuring that it meets the expectations outlined in the structure.\n",
      "\n",
      "If you would like to test this setup or need assistance with modification or further questions regarding its functionality, please provide more context on what you'd like to achieve!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith import Client\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "import os\n",
    "\n",
    "# Load API key\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "\n",
    "# Pull prompt from LangSmith\n",
    "hydrated_prompt = client.pull_prompt(\"prompt_hub\", include_model=True)\n",
    "\n",
    "# If it's a StructuredPrompt, extract the text/template\n",
    "if hasattr(hydrated_prompt, \"template\"):\n",
    "    prompt_text = hydrated_prompt.template\n",
    "else:\n",
    "    # fallback for RunnableSequence or other types\n",
    "    prompt_text = str(hydrated_prompt)\n",
    "\n",
    "# Convert to OpenAI message format\n",
    "converted_messages = convert_prompt_to_openai_format(prompt_text)[\"messages\"]\n",
    "\n",
    "# Call OpenAI\n",
    "openai_client = OpenAI()\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=converted_messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f02d00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:345: UserWarning: WARNING! extra_headers is not default parameter.\n",
      "                extra_headers was transferred to model_kwargs.\n",
      "                Please confirm that extra_headers is what you intended.\n",
      "  obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n"
     ]
    }
   ],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "prompt = client.pull_prompt(\"prompt_hub\", include_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6bf258e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredPrompt(input_variables=['language', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'prompt_hub', 'lc_hub_commit_hash': '56b6eb7b78b0ac3e1cc71bcd703e221fd2fe84b22e45f7642900a93fd898542b'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a women from mid 19th century, you only speak {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})], schema_={'title': 'answer', 'description': 'Extract the answer', 'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'Reply of llm to the user'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}, structured_output_kwargs={})\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x115b57800>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x115adfd50>, root_client=<openai.OpenAI object at 0x115b33d40>, root_async_client=<openai.AsyncOpenAI object at 0x115b06c60>, model_name='gpt-5-mini', temperature=1.0, model_kwargs={'extra_headers': {}}, openai_api_key=SecretStr('**********'), stream_usage=True, top_p=1.0), kwargs={'response_format': {'type': 'json_schema', 'json_schema': {'name': 'answer', 'description': 'Extract the answer', 'strict': True, 'schema': {'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'Reply of llm to the user'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}}}, 'ls_structured_output_format': {'kwargs': {'method': 'json_schema', 'strict': None}, 'schema': {'type': 'function', 'function': {'name': 'answer', 'description': 'Extract the answer', 'parameters': {'type': 'object', 'properties': {'answer': {'type': ['boolean', 'string'], 'description': 'Reply of llm to the user'}}, 'required': ['answer'], 'strict': True, 'additionalProperties': False}}}}}, config={}, config_factories=[])\n",
       "| JsonOutputParser()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3bcb421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'नहीं, मैं मतदान नहीं कर सकती। उस मध्य उन्नीसवीं सदी में महिलाओं को मतदान का अधिकार नहीं दिया जाता था।'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"question\": \"Can you vote?\", \"language\": \"Hindi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8e9683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "prompt = client.pull_prompt(\"prompt_hub:633cbde3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89c982ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CQEhP2N77VHgXBIslUt3KtXvOD3ip', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The world in the mid-19th century is a time of significant change and transformation. It is an era marked by industrialization, social reform, and the early stirrings of movements advocating for women\\'s rights. Many cities are rapidly expanding due to the growth of factories and the influx of people seeking jobs, leading to a dynamic but often difficult urban life.\\n\\nSocially, the roles of women are beginning to shift. While many women are still confined to traditional domestic roles, there are growing movements advocating for education, suffrage, and greater participation in public life. The notion of \"woman’s sphere\" is being challenged, with some women pushing against societal norms to demand equal rights.\\n\\nIn addition to these emerging social changes, there are also significant political movements occurring. Various countries are grappling with issues of freedom, democracy, and national identity. The abolitionist movement is gaining momentum in many places, striving to end slavery and promote equality.\\n\\nScientific and technological advancements are also transforming daily life, from the steam engine to telegraphs, making communication and transportation faster and more efficient than ever before.\\n\\nOverall, it is a time of both challenge and opportunity, where the foundations for future societal changes are being laid, setting the stage for the rights and freedoms that many of us women today are striving to achieve.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760369067, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=259, prompt_tokens=39, total_tokens=298, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith.client import convert_prompt_to_openai_format\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "hydrated_prompt = prompt.invoke({\"question\": \"What is the world like?\", \"language\": \"English\"})\n",
    "# NOTE: We can use this utility from LangSmith to convert our hydrated prompt to openai format\n",
    "converted_messages = convert_prompt_to_openai_format(hydrated_prompt)[\"messages\"]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=converted_messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f0be85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/french-rag-prompt/75567b82?organizationId=4d270e6c-941a-4ef1-a42f-90555c745c02'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "\n",
    "client=Client()\n",
    "\n",
    "french_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation.\n",
    "\n",
    "Your users can only speak French, make sure you only answer your users with French.\n",
    "\n",
    "Conversation: {conversation}\n",
    "Context: {context} \n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "french_prompt_template = ChatPromptTemplate.from_template(french_prompt)\n",
    "client.push_prompt(\"french-rag-prompt\", object=french_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bbc27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/french-runnable-sequence/2f90fdb7?organizationId=4d270e6c-941a-4ef1-a42f-90555c745c02'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langsmith import Client\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "client=Client()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "french_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation.\n",
    "\n",
    "Your users can only speak French, make sure you only answer your users with French.\n",
    "\n",
    "Conversation: {conversation}\n",
    "Context: {context} \n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "french_prompt_template = ChatPromptTemplate.from_template(french_prompt)\n",
    "chain = french_prompt_template | model\n",
    "client.push_prompt(\"french-runnable-sequence\", object=chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943dff3",
   "metadata": {},
   "source": [
    "We basically pushed the prompts using the programming itself without using the playground or the gui provided by the langsmith we can do tweaking in this too"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
